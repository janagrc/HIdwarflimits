{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from astropy.io import fits\n",
    "import astropy.units as u\n",
    "from astroquery import ned\n",
    "from astropy.wcs import wcs\n",
    "from astropy.coordinates import SkyCoord\n",
    "from astropy.table import Table, vstack, hstack\n",
    "import numpy as np\n",
    "import tables\n",
    "from tabulate import tabulate\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "from math import ceil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import mpld3\n",
    "mpld3.enable_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This is a cell with all self-defined functions\n",
    "def coord_NED(dwarfname):\n",
    "    from astroquery.ned.core import RemoteServiceError\n",
    "    # get rid of the weird symbos *, (, ), etc, since NED doens't like it\n",
    "    newname = dwarfname.replace('*','').replace('(','').replace(')', '')\n",
    "\n",
    "    try:\n",
    "        target = ned.Ned.query_object(newname)\n",
    "        ned_exist = True\n",
    "    except RemoteServiceError: \n",
    "        print('NED does not have info, skip: %s/%s\\n'%(dwarfname, newname))\n",
    "        ned_exist= False \n",
    "    \n",
    "    if ned_exist == False:\n",
    "        tRA, tDEC, tVel, tDist = np.nan, np.nan, np.nan, np.nan\n",
    "    else: # if NED does have this target, then extract coordinates\n",
    "        tRA = target[\"RA(deg)\"].data.data[0]\n",
    "        tDEC = target[\"DEC(deg)\"].data.data[0]\n",
    "        tVel = target[\"Velocity\"].data.data[0]\n",
    "        tDist = target[\"Distance (arcmin)\"].data.data[0]\n",
    "    return tRA, tDEC, tDist, tVel, ned_exist\n",
    "\n",
    "## transform from vhelio to vlsr \n",
    "def vhelio2vlsr_Westmeier(vel_init, ral, decb, reverse=False, doradec=True):\n",
    "    '''\n",
    "    - from http://www.atnf.csiro.au/people/Tobias.Westmeier/tools_hihelpers.php\n",
    "    - obj_ra:  should be in degree\n",
    "    - obj_dec: should be in degree\n",
    "    - vel_init: velocity that need to be transformed\n",
    "    -          vel_init = vhelio if reverse = False\n",
    "    -          vel_init = vlsr   if reverse = True\n",
    "    - Favor this one than the other one from Rosolowsky\n",
    "    '''\n",
    "    from astropy.coordinates import SkyCoord\n",
    "    import numpy as np\n",
    "\n",
    "    if doradec==True:\n",
    "        c = SkyCoord(ral, decb, unit='deg')\n",
    "        l = np.radians(c.galactic.l.value)\n",
    "        b = np.radians(c.galactic.b.value)\n",
    "    else:\n",
    "        l = np.radians(ral)\n",
    "        b = np.radians(decb)\n",
    "    # vlsr 00> vhelio\n",
    "    if reverse:\n",
    "        delv = -(9*np.cos(l)*np.cos(b)+12*np.sin(l)*np.cos(b)+7*np.sin(b))\n",
    "    else:\n",
    "        delv = +9*np.cos(l)*np.cos(b)+12*np.sin(l)*np.cos(b)+7*np.sin(b)\n",
    "\n",
    "    # print 'Velocity correction at this (RA, DEC) is (km/s): ', delv\n",
    "    return vel_init+delv\n",
    "\n",
    "\n",
    "def find_the_cube(ra, dec, observation='HI4PI'):\n",
    "    '''\n",
    "    Use the input (ra, dec) to decide which cube the data locates.\n",
    "\n",
    "    observation: most of the time, it is HI4PI or GALFA-HI . \n",
    "    \n",
    "    Note: GALFA-HI table is not available now, will do later \n",
    "    '''\n",
    "\n",
    "    clt = Table.read('tables/%s_RADEC.dat'%(observation), format='ascii')\n",
    "    cramin, cramax = clt['min_ra'], clt['max_ra']\n",
    "    cdcmin, cdcmax = clt['min_dec'], clt['max_dec']\n",
    "    indra = np.all([ra>cramin, ra<cramax], axis=0)\n",
    "    inddc = np.all([dec>cdcmin, dec<cdcmax], axis=0)\n",
    "    indall = np.where(np.all([indra, inddc], axis=0) == True)\n",
    "\n",
    "    cubename = clt['cubename'][indall]\n",
    "    if len(cubename)==0:\n",
    "        return ''\n",
    "    else:\n",
    "        cubename = cubename[0]\n",
    "\n",
    "        return cubename\n",
    "    \n",
    "import sys\n",
    "import astropy.wcs as wcs\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# a function to read in header and generate RA, DEC and VLSR array\n",
    "def get_cubeinfo(header, returnHeader=False):\n",
    "    '''\n",
    "    A function created to parse the RA, DEC, (and velocity) information from the 2D (3D) header\n",
    "\n",
    "    - This function has been tested with GALFA-HI/EBHIS cubes, and GALFA-HI 2D images.\n",
    "    -               also been tested with LAB cubes/images that are in (glon, glat) coordinates.\n",
    "    - The input header can be 2D: NAXIS=2. NAXIS1 is RA (glon), 2 is DEC (glat)\n",
    "    -                      or 3D: NAXIS=3. NAXIS1 is RA (glon), 2 is DEC (glat), 3 is Velocity\n",
    "    - Return: if GALFA-HI or EBHIS:\n",
    "                        ra and dec in 2D, with shape of (dec.size, ra.size) or (NAXIS2, NAXIS1)\n",
    "    -                   velocity in 1D.\n",
    "                        or (ra, dec, vlsr, header array)\n",
    "    -         if LAB:\n",
    "                        glon, glat in 2D, with shape of (glat.size, glon.size) or (NAXIS2, NAXIS1)\n",
    "    -                   velocity in 1D.\n",
    "                        or (gl, gb, vlsr, header array)\n",
    "    - History: updated as of 2016.10.03. Yong Zheng @ Columbia Astro.\n",
    "    '''\n",
    "\n",
    "\n",
    "    hdrarrs = []\n",
    "    if header['NAXIS'] == 2:\n",
    "        hdr2d = header.copy()\n",
    "        hdrarrs.append(hdr2d)\n",
    "    elif header['NAXIS'] == 3:\n",
    "        # create a 2D header (RA/DEC) to speed up the RA/DEC calculation using astropy.wcs\n",
    "        hdr2d = header.copy()\n",
    "        # we don't need the velocity (3) information in the header\n",
    "        delkey = []\n",
    "        for key in hdr2d.keys():\n",
    "            if len(key) != 0 and key[-1] == '3': delkey.append(key)\n",
    "        for i in delkey: del hdr2d[i]\n",
    "\n",
    "        hdr2d['NAXIS'] = 2\n",
    "        if 'WCSAXES' in hdr2d.keys(): hdr2d['WCSAXES']=2\n",
    "        # create a 1D header (vel) to parse the velocity using astropy.wcs\n",
    "        hdr1d = header.copy()\n",
    "        # we don't need the RA/DEC keywords info in the header now.\n",
    "        delkey = []\n",
    "        for keya in hdr1d.keys():\n",
    "            if len(keya) != 0 and keya[-1] in ['1', '2']: delkey.append(keya)\n",
    "        for i in delkey: del hdr1d[i]\n",
    "        delkey = []\n",
    "        for keyb in hdr1d.keys():\n",
    "            if len(keyb) != 0 and keyb[-1] == '3':\n",
    "                hdr1d.append('%s1'%(keyb[:-1]))\n",
    "                hdr1d['%s1'%(keyb[:-1])] = hdr1d[keyb]\n",
    "                delkey.append(keyb)\n",
    "        for i in delkey: del hdr1d[i]\n",
    "        hdr1d['NAXIS'] = 1\n",
    "        if 'WCSAXES' in hdr1d.keys(): hdr1d['WCSAXES']=1\n",
    "\n",
    "        # save header arrays\n",
    "        hdrarrs.append(hdr2d)\n",
    "        hdrarrs.append(hdr1d)\n",
    "    else:\n",
    "        print(\"This code can only handle 2D or 3D data\")\n",
    "        sys.exit(1)\n",
    "\n",
    "    return_arrays = []\n",
    "\n",
    "    # calculate RA, DEC\n",
    "    gwcsa = wcs.WCS(hdr2d)\n",
    "    n1, n2 = hdr2d['NAXIS1'], hdr2d['NAXIS2']\n",
    "    ax = np.reshape(np.mgrid[0:n1:1]+1, (1, n1))  # For FITS standard, origin = 1\n",
    "    ay = np.reshape(np.mgrid[0:n2:1]+1, (n2, 1))  #   then for numpy standard, origin = 0\n",
    "    coor1, coor2 = gwcsa.all_pix2world(ax, ay, 1) # coor1 = ra  or glon\n",
    "    return_arrays.append(coor1)                   # coor2 = dec or glat\n",
    "    return_arrays.append(coor2)\n",
    "\n",
    "    ## calculate VLSR\n",
    "    if header['NAXIS'] == 3:\n",
    "        gwcsb = wcs.WCS(hdr1d)\n",
    "        n1 = hdr1d['NAXIS1']\n",
    "        ax = np.mgrid[0:n1:1]+1\n",
    "        # ax = np.linspace(0, n1, n1)  # nope, wrong\n",
    "        vel = gwcsb.all_pix2world(ax, 1)[0]\n",
    "        if 'CUNIT1' in hdr1d.keys():\n",
    "            if hdr1d['CUNIT1'] in ['m/s', 'M/S', 'M/s', 'm/S']:\n",
    "                vel = vel/1e3\n",
    "        else: vel = vel/1e3  # default is usually in m/s\n",
    "        return_arrays.append(vel)\n",
    "\n",
    "    if returnHeader == True: return_arrays.append(hdrarrs)\n",
    "    return return_arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ellipse_mask_cube(semi_a, semi_b, PA, tar_x, tar_y, cube_header, extend_pix = 0):\n",
    "    ## make ellipse based on the semi major/minor axies and position angle of the targets \n",
    "    \n",
    "    cube_wh = cube_header['NAXIS1']  # RA\n",
    "    cube_ht = cube_header['NAXIS2']  # DEC\n",
    "    x1d = np.arange(cube_wh)\n",
    "    y1d = np.arange(cube_ht)\n",
    "    x2d, y2d = np.meshgrid(x1d, y1d)\n",
    "\n",
    "    # center at the source \n",
    "    x2d_nc, y2d_nc = x2d-tar_x, y2d-tar_y\n",
    "\n",
    "    # this is a rough pixel length for the semimajor and semiminor axis\n",
    "    semi_a_pix = ceil(abs(semi_a / cube_header['CDELT1']))\n",
    "    semi_b_pix = ceil(abs(semi_b / cube_header['CDELT1']))\n",
    "    \n",
    "    #phi = np.radians(90-PA) changing \n",
    "    phi = np.radians(90+PA)\n",
    "\n",
    "    # transform to new coordinate system\n",
    "    xx_prime = x2d_nc*np.cos(phi) + y2d_nc*np.sin(phi)\n",
    "    yy_prime = -x2d_nc*np.sin(phi) + y2d_nc*np.cos(phi)\n",
    "\n",
    "    mask_ep = ((xx_prime/(semi_a_pix+extend_pix))**2 + (yy_prime/(semi_b_pix+extend_pix))**2)<=1 \n",
    "    return mask_ep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_info(objname):\n",
    "    from astropy.table import Table \n",
    "    tb = Table.read('/Users/amalyajohnson/Desktop/astro/Dwarf Galaxies/dwarfgalcomplete.txt', format='ascii')\n",
    "    \n",
    "    newname = objname.replace('*','').replace('(','').replace(')', '').replace(' ', '')\n",
    "    for i, iname in enumerate(tb['GalaxyName']):\n",
    "        i_tbnewname = iname.replace('*','').replace('(','').replace(')', '').replace(' ', '')\n",
    "        \n",
    "        if newname == i_tbnewname:\n",
    "            find_it = True\n",
    "            break\n",
    "        else: \n",
    "            find_it = False\n",
    "            \n",
    "    if find_it == True:\n",
    "        print('YES, we find it!!!', tb['RA'][i], tb['DEC'][i], tb['vh(m/s)'][i])\n",
    "        return tb['RA'][i], tb['DEC'][i], tb['vh(m/s)'][i], tb['rh(arcmins)'][i], tb['e=1-b/a'][i], tb['PA'][i]\n",
    "    else:\n",
    "        print('Sorry, not there, check your object name. ')\n",
    "        return np.nan, np.nan, np.nan\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Galaxy Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YES, we find it!!! 19.1208 33.4192 -192400\n"
     ]
    }
   ],
   "source": [
    "objname = 'AndromedaII' \n",
    "\n",
    "objRA, objDEC, objV_helio, a, ecc, PA = find_info(objname)\n",
    "vcoord = vhelio2vlsr_Westmeier(0, objRA, objDEC, doradec=True) #in km/s\n",
    "objV = objV_helio + vcoord*1e3\n",
    "semi_b = (1 - ecc)*a/60 #degree, semi minor axis\n",
    "semi_a = a/60 #degree, semi major axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: VerifyWarning: Invalid 'BLANK' keyword in header.  The 'BLANK' keyword is only applicable to integer data, and will be ignored in this HDU. [astropy.io.fits.hdu.image]\n"
     ]
    }
   ],
   "source": [
    "cubename = '/Users/amalyajohnson/Desktop/datacubes/GALFA_HI_RA+DEC_020.00+34.35_W' #pull correct cube from directory\n",
    "img1 = fits.getdata(cubename)\n",
    "hdr = fits.getheader(cubename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: FITSFixedWarning: 'spcfix' made the change 'Changed CTYPE3 from 'VELO-LSR' to 'VOPT''. [astropy.wcs.wcs]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((2048, 512, 512), 761, 308, 199)"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# setting up the WCS\n",
    "wcsleop =  wcs.WCS(hdr)\n",
    "\n",
    "# converting to pixel space\n",
    "tar_x, tar_y, tar_v = wcsleop.all_world2pix(objRA, objDEC, objV, 0)\n",
    "tar_x = int(tar_x)\n",
    "tar_y = int(tar_y)\n",
    "tar_v = int(tar_v)\n",
    "\n",
    "# & checking it's in there, make sure the shape fits the size of tar_v, tar_x, tar_y\n",
    "img1.shape,  tar_v, tar_x, tar_y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# figure out how large the area surrounding the source that we want \n",
    "ep1 = ellipse_mask_cube(semi_a, semi_b, PA, tar_x, tar_y, hdr, extend_pix=0) #optical size\n",
    "ep2 = ellipse_mask_cube(.25, .25, PA, tar_x, tar_y, hdr, extend_pix=0) #30arcmin diameter\n",
    "#increase ep 2 to .5, .5 ? \n",
    "\n",
    "a = img1[tar_v][ep1]\n",
    "b = img1[tar_v][ep2]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stdev 30 arcmin, median over 10 channels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def GaussSM_image(image, H_beam=16.2, G_beam=4): \n",
    "    ## the image is at the velocity channel of the dwarf \n",
    "    ## H_beam: HI4PI beam size in arcmin \n",
    "    ## G_beam: GALFA-HI beam size in arcmin \n",
    "    \n",
    "    import numpy as np\n",
    "    from scipy.ndimage import gaussian_filter\n",
    "    \n",
    "    pix_size = 1 # GALFA-HI pixel size, in arcmin \n",
    "    convl_beam = np.sqrt(H_beam**2 - G_beam**2) # FWHM\n",
    "    sigma = convl_beam/2.355/pix_size ## kernel size in pixel, FWHM=2.355sigma\n",
    "    return gaussian_filter(image, sigma=sigma)\n",
    "\n",
    "\n",
    "# sm_img = GaussSM_image(img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "b_1s = GaussSM_image(img1[tar_v-5], H_beam = 8) #change h_beam = 8 when calling \n",
    "b_2s = GaussSM_image(img1[tar_v-4], H_beam = 8)\n",
    "b_3s = GaussSM_image(img1[tar_v-3], H_beam = 8)\n",
    "b_4s = GaussSM_image(img1[tar_v-2], H_beam = 8)\n",
    "b_5s = GaussSM_image(img1[tar_v-1], H_beam = 8)\n",
    "b_6s = GaussSM_image(img1[tar_v], H_beam = 8)\n",
    "b_7s = GaussSM_image(img1[tar_v+1], H_beam = 8)\n",
    "b_8s = GaussSM_image(img1[tar_v+2], H_beam = 8)\n",
    "b_9s = GaussSM_image(img1[tar_v+3], H_beam = 8)\n",
    "b_10s = GaussSM_image(img1[tar_v+4], H_beam = 8)\n",
    "b_11s = GaussSM_image(img1[tar_v+5], H_beam = 8)\n",
    "\n",
    "b_1 = b_1s[ep2]\n",
    "b_2 = b_2s[ep2]\n",
    "b_3 = b_3s[ep2]\n",
    "b_4 = b_4s[ep2]\n",
    "b_5 = b_5s[ep2]\n",
    "b_6 = b_6s[ep2]\n",
    "b_7 = b_7s[ep2]\n",
    "b_8 = b_8s[ep2]\n",
    "b_9 = b_9s[ep2]\n",
    "b_10 = b_10s[ep2]\n",
    "b_11 = b_11s[ep2]\n",
    "\n",
    "brange = np.array([b_1, b_2, b_3, b_4, b_5, b_6, b_7, b_8, b_9, b_10, b_11])\n",
    "brange_std = np.array([np.nanstd(b_1), np.nanstd(b_2), np.nanstd(b_3), np.nanstd(b_4), \n",
    "                       np.nanstd(b_5), np.nanstd(b_6), np.nanstd(b_7), np.nanstd(b_8), \n",
    "                       np.nanstd(b_9), np.nanstd(b_10), np.nanstd(b_11)])\n",
    "\n",
    "std_b = np.nanstd(b)\n",
    "med_stdb = np.nanmedian(brange_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Smoothed Image: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 8))\n",
    "im = plt.imshow(img1_sm[:, :], cmap='jet', origin='lower' , vmin=-.2, vmax=.2)\n",
    "#plt.contour(ep1, colors='white')\n",
    "plt.contour(ep2, colors='r')\n",
    "plt.text(tar_x+15, tar_y+15, objname, color='w', fontsize=14, weight='semibold')\n",
    "plt.title(objname)\n",
    "plt.colorbar(im)\n",
    "\n",
    "#plt.savefig('/Users/amalyajohnson/Desktop/smooth_images/%s_smoothed.pdf'%(objname)) #to save file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MHI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "651.628 AndromedaII\n"
     ]
    }
   ],
   "source": [
    "def dist(objname):\n",
    "    tbm = Table.read('/Users/amalyajohnson/Desktop/astro/Dwarf Galaxies/dwarfgalcomplete_newnew.txt', format='ascii')\n",
    "    for i, iname in enumerate(tbm['GalaxyName']):\n",
    "        if iname == objname:\n",
    "            find_it = True\n",
    "            break \n",
    "        else: \n",
    "            find_it = False\n",
    "        \n",
    "    if find_it == True:\n",
    "        dist = float(tbm['dist(kpc)'][i])\n",
    "        return dist \n",
    "print(dist(objname), objname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unresolved (Now Unresolved Because Smoothing Cubes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'8866.38070'"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MHI = (2.36x10**5)(D**2 mpc)(Stot) \n",
    "x = 2.36*1e5\n",
    "dmpc = dist(objname)/1e3  #mpc \n",
    "flux = med_stdb #using median of standard deviation\n",
    "stot = flux*10 #tflux always multiplied by 10km/s\n",
    "\n",
    "#galfa: 9.1 k/Jy hi4pi: .6 jy/k\n",
    "g = 1/9.1 \n",
    "h = .6\n",
    "g_s = .44  #smoothed galfa data to hi4pi, conversion factor \n",
    "\n",
    "\n",
    "MHI = x*(dmpc**2)*(stot*g_s) #multiply by 'h' or 'g' or 'g_s' (hi4pi, galfa, galfa smoothed) to convert to janskys \n",
    "y = MHI\n",
    "MHI = '%.5f'%(y)\n",
    "MHI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table: galfa_resolved_undetected_table.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['AndromedaII', '0.020109', '0.029312', '0.026191', '0.022482',\n",
       "       '0.018270', '0.015435', '0.016636', '0.020109', '0.022511',\n",
       "       '0.022071', '0.019459', '0.017692', '8866.38070'], \n",
       "      dtype='<U11')"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rowd = np.array([objname, '%.6f'%(med_stdb), '%.6f'%(np.nanstd(b_1)), '%.6f'%(np.nanstd(b_2)), '%.6f'%(np.nanstd(b_3)), '%.6f'%(np.nanstd(b_4)), \n",
    "                       '%.6f'%(np.nanstd(b_5)), '%.6f'%(np.nanstd(b_6)), '%.6f'%(np.nanstd(b_7)), '%.6f'%(np.nanstd(b_8)), \n",
    "                       '%.6f'%(np.nanstd(b_9)), '%.6f'%(np.nanstd(b_10)), '%.6f'%(np.nanstd(b_11)), MHI])\n",
    "\n",
    "rowd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "&lt;Table length=13&gt;\n",
       "<table id=\"table6784040800\" class=\"table-striped table-bordered table-condensed\">\n",
       "<thead><tr><th>GalaxyName</th><th>med_std</th><th>v_-5</th><th>v_-4</th><th>v_-3</th><th>v_-2</th><th>v_-1</th><th>v_0</th><th>v_+1</th><th>v_+2</th><th>v_+3</th><th>v_+4</th><th>v_+5</th><th>MHI_limit</th></tr></thead>\n",
       "<thead><tr><th>str11</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th></tr></thead>\n",
       "<tr><td>Segue(I)</td><td>0.017123</td><td>0.020954</td><td>0.020997</td><td>0.019659</td><td>0.01838</td><td>0.017681</td><td>0.017123</td><td>0.016192</td><td>0.014794</td><td>0.013582</td><td>0.012936</td><td>0.012643</td><td>9.33124</td></tr>\n",
       "<tr><td>TriangulumI</td><td>0.03336</td><td>0.03231</td><td>0.03548</td><td>0.041173</td><td>0.044659</td><td>0.043152</td><td>0.037963</td><td>0.03336</td><td>0.031326</td><td>0.029874</td><td>0.027878</td><td>0.025896</td><td>31.59335</td></tr>\n",
       "<tr><td>BootesII</td><td>0.020185</td><td>0.026547</td><td>0.024216</td><td>0.020185</td><td>0.016058</td><td>0.013231</td><td>0.013089</td><td>0.015978</td><td>0.019443</td><td>0.021502</td><td>0.02289</td><td>0.023712</td><td>36.42427</td></tr>\n",
       "<tr><td>SegueII</td><td>0.019513</td><td>0.019513</td><td>0.021121</td><td>0.021463</td><td>0.019757</td><td>0.01738</td><td>0.016138</td><td>0.016102</td><td>0.016821</td><td>0.01815</td><td>0.019659</td><td>0.020971</td><td>24.36055</td></tr>\n",
       "<tr><td>ComaBerenic</td><td>0.011513</td><td>0.017993</td><td>0.018037</td><td>0.017272</td><td>0.016089</td><td>0.014207</td><td>0.011513</td><td>0.009089</td><td>0.007597</td><td>0.006588</td><td>0.006316</td><td>0.006658</td><td>22.78042</td></tr>\n",
       "<tr><td>Bootes(I)</td><td>0.024946</td><td>0.020448</td><td>0.019055</td><td>0.019703</td><td>0.021678</td><td>0.023773</td><td>0.025247</td><td>0.025994</td><td>0.026299</td><td>0.026131</td><td>0.025314</td><td>0.024946</td><td>114.12019</td></tr>\n",
       "<tr><td>Hercules</td><td>0.028245</td><td>0.027603</td><td>0.028245</td><td>0.02947</td><td>0.030828</td><td>0.031628</td><td>0.031415</td><td>0.029572</td><td>0.026164</td><td>0.023573</td><td>0.024793</td><td>0.027962</td><td>509.70036</td></tr>\n",
       "<tr><td>LeoIV</td><td>0.018579</td><td>0.023945</td><td>0.019971</td><td>0.017264</td><td>0.017018</td><td>0.018579</td><td>0.0195</td><td>0.01931</td><td>0.018564</td><td>0.018563</td><td>0.019044</td><td>0.0184</td><td>458.54783</td></tr>\n",
       "<tr><td>CanesVenati</td><td>0.016252</td><td>0.024369</td><td>0.021633</td><td>0.018487</td><td>0.016273</td><td>0.015959</td><td>0.016252</td><td>0.016039</td><td>0.015467</td><td>0.015233</td><td>0.015825</td><td>0.016702</td><td>800.34072</td></tr>\n",
       "<tr><td>LeoI</td><td>0.031631</td><td>0.029137</td><td>0.030867</td><td>0.033413</td><td>0.036775</td><td>0.037608</td><td>0.034692</td><td>0.030318</td><td>0.027769</td><td>0.028897</td><td>0.031631</td><td>0.032785</td><td>2110.97076</td></tr>\n",
       "<tr><td>AndromedaXI</td><td>0.038535</td><td>0.039503</td><td>0.039608</td><td>0.039136</td><td>0.038333</td><td>0.038535</td><td>0.039022</td><td>0.037862</td><td>0.035554</td><td>0.034288</td><td>0.03559</td><td>0.039367</td><td>26928.92868</td></tr>\n",
       "<tr><td>AndromedaII</td><td>0.020109</td><td>0.029312</td><td>0.026191</td><td>0.022482</td><td>0.01827</td><td>0.015435</td><td>0.016636</td><td>0.020109</td><td>0.022511</td><td>0.022071</td><td>0.019459</td><td>0.017692</td><td>8866.3807</td></tr>\n",
       "<tr><td>AndromedaII</td><td>0.020109</td><td>0.029312</td><td>0.026191</td><td>0.022482</td><td>0.01827</td><td>0.015435</td><td>0.016636</td><td>0.020109</td><td>0.022511</td><td>0.022071</td><td>0.019459</td><td>0.017692</td><td>8866.3807</td></tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Table length=13>\n",
       " GalaxyName med_std    v_-5     v_-4   ...   v_+4     v_+5    MHI_limit \n",
       "   str11    float64  float64  float64  ... float64  float64    float64  \n",
       "----------- -------- -------- -------- ... -------- -------- -----------\n",
       "   Segue(I) 0.017123 0.020954 0.020997 ... 0.012936 0.012643     9.33124\n",
       "TriangulumI  0.03336  0.03231  0.03548 ... 0.027878 0.025896    31.59335\n",
       "   BootesII 0.020185 0.026547 0.024216 ...  0.02289 0.023712    36.42427\n",
       "    SegueII 0.019513 0.019513 0.021121 ... 0.019659 0.020971    24.36055\n",
       "ComaBerenic 0.011513 0.017993 0.018037 ... 0.006316 0.006658    22.78042\n",
       "  Bootes(I) 0.024946 0.020448 0.019055 ... 0.025314 0.024946   114.12019\n",
       "   Hercules 0.028245 0.027603 0.028245 ... 0.024793 0.027962   509.70036\n",
       "      LeoIV 0.018579 0.023945 0.019971 ... 0.019044   0.0184   458.54783\n",
       "CanesVenati 0.016252 0.024369 0.021633 ... 0.015825 0.016702   800.34072\n",
       "       LeoI 0.031631 0.029137 0.030867 ... 0.031631 0.032785  2110.97076\n",
       "AndromedaXI 0.038535 0.039503 0.039608 ...  0.03559 0.039367 26928.92868\n",
       "AndromedaII 0.020109 0.029312 0.026191 ... 0.019459 0.017692   8866.3807\n",
       "AndromedaII 0.020109 0.029312 0.026191 ... 0.019459 0.017692   8866.3807"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tbnew = Table(names=('GalaxyName', 'med_std', 'v_-5', 'v_-4', 'v_-3', 'v_-2', \n",
    "#                      'v_-1', 'v_0', 'v_+1', 'v_+2', 'v_+3', 'v_+4', 'v_+5', 'MHI_limit'), \n",
    "#             meta={'name': 'first table'},\n",
    "#             dtype=('<U11', 'f8', 'f8', 'f8', 'f8', 'f8', 'f8', 'f8', 'f8', 'f8', 'f8', 'f8', 'f8', 'f8'))\n",
    "tbnew.add_row(rowd)\n",
    "\n",
    "tbnew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('galfa_resolved_undetected_table2.txt', 'w')\n",
    "Table = tbnew\n",
    "f.write(tabulate(tbnew))\n",
    "f.close\n",
    "\n",
    "tbnew.show_in_browser()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OLD: Calculating Total Flux Through Each Ellipse "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##hi4pi pixel size: 4 arcmin\n",
    "\n",
    "#hi4pi = 4/60                  #conversion to degree\n",
    "#semi_apix = semi_a/hi4pi      #how large the semi major axis is in pixels\n",
    "#ex = 2*semi_apix              #placing the extra ellipses just off the optical location\n",
    "\n",
    "##galfa pixel size: 1 arcmin\n",
    "\n",
    "galfa = 1/60                #conversion to degree\n",
    "semi_apix = semi_a/galfa    #how large the semi major axis is in pixels\n",
    "ex = 2*semi_apix             #placing the extra ellipses just off the optical location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#8 ellipses surrounding the optical location, numbered counterclockwise\n",
    "ep_1 = ellipse_mask_cube(semi_a, semi_b, PA, tar_x+ex, tar_y, hdr, extend_pix=0) \n",
    "ep_2 = ellipse_mask_cube(semi_a, semi_b, PA, tar_x+ex, tar_y+ex, hdr, extend_pix=0)\n",
    "ep_3 = ellipse_mask_cube(semi_a, semi_b, PA, tar_x, tar_y+ex, hdr, extend_pix=0)\n",
    "ep_4 = ellipse_mask_cube(semi_a, semi_b, PA, tar_x-ex, tar_y+ex, hdr, extend_pix=0)\n",
    "ep_5 = ellipse_mask_cube(semi_a, semi_b, PA, tar_x-ex, tar_y, hdr, extend_pix=0)\n",
    "ep_6 = ellipse_mask_cube(semi_a, semi_b, PA, tar_x-ex, tar_y-ex, hdr, extend_pix=0)\n",
    "ep_7 = ellipse_mask_cube(semi_a, semi_b, PA, tar_x, tar_y-ex, hdr, extend_pix=0)\n",
    "ep_8 = ellipse_mask_cube(semi_a, semi_b, PA, tar_x+ex, tar_y-ex, hdr, extend_pix=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = 0  #x = 0 : just looking at central velocity channel, x = 10, going through +/- 5 velocity channels\n",
    "full_chan = tar_v + np.arange(x+1) - ceil(x/2) #summing flux through +/- x/2 velocity channels \n",
    "\n",
    "def fluxi(objname, epi): #Function to produce an array of total flux through each ellipse\n",
    "\n",
    "    vrange = []\n",
    "    vrange_tflux = []\n",
    "    for f in full_chan:                  #f goes from -full_chan/2 to full_chan/2\n",
    "        #img1_sm = GaussSM_image(img1[f])\n",
    "        #v_chan = img1_sm[epi]\n",
    "        v_chan = img1[f][epi]\n",
    "        v_tflux = np.nansum(v_chan)      #sum of flux through ellipse \"i\" in velocity channel \"f\"\n",
    "        vrange.append(v_chan)\n",
    "        vrange_tflux.append(v_tflux)\n",
    "        ttflux = np.nansum(vrange_tflux) #total flux through all 10 velocity channels \n",
    "    return ttflux\n",
    "\n",
    "tflux_8ep = []\n",
    "for epi in [ep1, ep_1, ep_2, ep_3, ep_4, ep_5, ep_6, ep_7, ep_8]:\n",
    "    \n",
    "    tflux = np.nansum(fluxi(objname, epi))  #calling fluxi on ellipses 1 through 8, ep1 = central location \n",
    "    tflux_8ep.append(tflux)                 #putting this result into array for 8 ellipses\n",
    "    \n",
    "\n",
    "np.nanstd(tflux_8ep)  #standard deviation of 9 ellipses (last column in table)\n",
    "    \n",
    "#array of object name, standard deviation of 9 ellipses, and total flux of each ellipse \n",
    "rowf = ([objname, '%.5f'%(np.nanstd(tflux_8ep)),'%.5f'%(fluxi(objname, ep1)), \n",
    "         '%.5f'%(fluxi(objname, ep_1)), '%.5f'%(fluxi(objname, ep_2)), '%.5f'%(fluxi(objname, ep_3)),\n",
    "         '%.5f'%(fluxi(objname, ep_4)), '%.5f'%(fluxi(objname, ep_5)), '%.5f'%(fluxi(objname, ep_6)),\n",
    "         '%.5f'%(fluxi(objname, ep_7)),'%.5f'%(fluxi(objname, ep_8))])  \n",
    "\n",
    "\n",
    "np.nanstd(tflux_8ep)\n",
    "#something changed here, idk what I did \n",
    "rowf, np.nanstd(tflux_8ep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 8))\n",
    "im = plt.imshow(img1[tar_v, :, :], cmap='jet', origin='lower' , vmin=-.5, vmax=.5)\n",
    "plt.contour(ep1, colors='white')\n",
    "plt.contour(ep2, colors='r')\n",
    "plt.text(tar_x+15, tar_y+15, objname, color='w', fontsize=14, weight='semibold')\n",
    "plt.title(objname)\n",
    "plt.colorbar(im)\n",
    "\n",
    "#outline of 8 surrounding ellipses\n",
    "plt.contour(ep_1, colors='k', alpha=.3)\n",
    "plt.contour(ep_2, colors='k', alpha=.3)\n",
    "plt.contour(ep_3, colors='k', alpha=.3)\n",
    "plt.contour(ep_4, colors='k', alpha=.3)\n",
    "plt.contour(ep_5, colors='k', alpha=.3)\n",
    "plt.contour(ep_6, colors='k', alpha=.3)\n",
    "plt.contour(ep_7, colors='k', alpha=.3)\n",
    "plt.contour(ep_8, colors='k', alpha=.3)\n",
    "\n",
    "#plt.xlim(0, 50)\n",
    "#plt.ylim(75, 125)\n",
    "\n",
    "#plt.savefig('/Users/amalyajohnson/Desktop/images/resolved undetected/%s_resolvedundetected.pdf'%(objname)') #to save file\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
