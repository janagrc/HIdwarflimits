{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import mpld3\n",
    "mpld3.enable_notebook()\n",
    "\n",
    "from astropy.io import fits\n",
    "import astropy.units as u\n",
    "from astroquery import ned\n",
    "from astropy.wcs import wcs\n",
    "from astropy.coordinates import SkyCoord\n",
    "from astropy.table import Table, vstack, hstack\n",
    "import numpy as np\n",
    "import tables\n",
    "from tabulate import tabulate\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "from math import ceil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This is a cell with all self-defined functions\n",
    "def coord_NED(dwarfname):\n",
    "    from astroquery.ned.core import RemoteServiceError\n",
    "    # get rid of the weird symbos *, (, ), etc, since NED doens't like it\n",
    "    newname = dwarfname.replace('*','').replace('(','').replace(')', '')\n",
    "\n",
    "    try:\n",
    "        target = ned.Ned.query_object(newname)\n",
    "        ned_exist = True\n",
    "    except RemoteServiceError: \n",
    "        print('NED does not have info, skip: %s/%s\\n'%(dwarfname, newname))\n",
    "        ned_exist= False \n",
    "    \n",
    "    if ned_exist == False:\n",
    "        tRA, tDEC, tVel, tDist = np.nan, np.nan, np.nan, np.nan\n",
    "    else: # if NED does have this target, then extract coordinates\n",
    "        tRA = target[\"RA(deg)\"].data.data[0]\n",
    "        tDEC = target[\"DEC(deg)\"].data.data[0]\n",
    "        tVel = target[\"Velocity\"].data.data[0]\n",
    "        tDist = target[\"Distance (arcmin)\"].data.data[0]\n",
    "    return tRA, tDEC, tDist, tVel, ned_exist\n",
    "\n",
    "## transform from vhelio to vlsr \n",
    "def vhelio2vlsr_Westmeier(vel_init, ral, decb, reverse=False, doradec=True):\n",
    "    '''\n",
    "    - from http://www.atnf.csiro.au/people/Tobias.Westmeier/tools_hihelpers.php\n",
    "    - obj_ra:  should be in degree\n",
    "    - obj_dec: should be in degree\n",
    "    - vel_init: velocity that need to be transformed\n",
    "    -          vel_init = vhelio if reverse = False\n",
    "    -          vel_init = vlsr   if reverse = True\n",
    "    - Favor this one than the other one from Rosolowsky\n",
    "    '''\n",
    "    from astropy.coordinates import SkyCoord\n",
    "    import numpy as np\n",
    "\n",
    "    if doradec==True:\n",
    "        c = SkyCoord(ral, decb, unit='deg')\n",
    "        l = np.radians(c.galactic.l.value)\n",
    "        b = np.radians(c.galactic.b.value)\n",
    "    else:\n",
    "        l = np.radians(ral)\n",
    "        b = np.radians(decb)\n",
    "    # vlsr 00> vhelio\n",
    "    if reverse:\n",
    "        delv = -(9*np.cos(l)*np.cos(b)+12*np.sin(l)*np.cos(b)+7*np.sin(b))\n",
    "    else:\n",
    "        delv = +9*np.cos(l)*np.cos(b)+12*np.sin(l)*np.cos(b)+7*np.sin(b)\n",
    "\n",
    "    # print 'Velocity correction at this (RA, DEC) is (km/s): ', delv\n",
    "    return vel_init+delv\n",
    "\n",
    "\n",
    "def find_the_cube(ra, dec, observation='HI4PI'):\n",
    "    '''\n",
    "    Use the input (ra, dec) to decide which cube the data locates.\n",
    "\n",
    "    observation: most of the time, it is HI4PI or GALFA-HI . \n",
    "    \n",
    "    Note: GALFA-HI table is not available now, will do later \n",
    "    '''\n",
    "\n",
    "    clt = Table.read('tables/%s_RADEC.dat'%(observation), format='ascii')\n",
    "    cramin, cramax = clt['min_ra'], clt['max_ra']\n",
    "    cdcmin, cdcmax = clt['min_dec'], clt['max_dec']\n",
    "    indra = np.all([ra>cramin, ra<cramax], axis=0)\n",
    "    inddc = np.all([dec>cdcmin, dec<cdcmax], axis=0)\n",
    "    indall = np.where(np.all([indra, inddc], axis=0) == True)\n",
    "\n",
    "    cubename = clt['cubename'][indall]\n",
    "    if len(cubename)==0:\n",
    "        return ''\n",
    "    else:\n",
    "        cubename = cubename[0]\n",
    "\n",
    "        return cubename\n",
    "    \n",
    "import sys\n",
    "import astropy.wcs as wcs\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# a function to read in header and generate RA, DEC and VLSR array\n",
    "def get_cubeinfo(header, returnHeader=False):\n",
    "    '''\n",
    "    A function created to parse the RA, DEC, (and velocity) information from the 2D (3D) header\n",
    "\n",
    "    - This function has been tested with GALFA-HI/EBHIS cubes, and GALFA-HI 2D images.\n",
    "    -               also been tested with LAB cubes/images that are in (glon, glat) coordinates.\n",
    "    - The input header can be 2D: NAXIS=2. NAXIS1 is RA (glon), 2 is DEC (glat)\n",
    "    -                      or 3D: NAXIS=3. NAXIS1 is RA (glon), 2 is DEC (glat), 3 is Velocity\n",
    "    - Return: if GALFA-HI or EBHIS:\n",
    "                        ra and dec in 2D, with shape of (dec.size, ra.size) or (NAXIS2, NAXIS1)\n",
    "    -                   velocity in 1D.\n",
    "                        or (ra, dec, vlsr, header array)\n",
    "    -         if LAB:\n",
    "                        glon, glat in 2D, with shape of (glat.size, glon.size) or (NAXIS2, NAXIS1)\n",
    "    -                   velocity in 1D.\n",
    "                        or (gl, gb, vlsr, header array)\n",
    "    - History: updated as of 2016.10.03. Yong Zheng @ Columbia Astro.\n",
    "    '''\n",
    "\n",
    "    #import sys\n",
    "    #import astropy.wcs as wcs\n",
    "    #import numpy as np\n",
    "\n",
    "\n",
    "    hdrarrs = []\n",
    "    if header['NAXIS'] == 2:\n",
    "        hdr2d = header.copy()\n",
    "        hdrarrs.append(hdr2d)\n",
    "    elif header['NAXIS'] == 3:\n",
    "        # create a 2D header (RA/DEC) to speed up the RA/DEC calculation using astropy.wcs\n",
    "        hdr2d = header.copy()\n",
    "        # we don't need the velocity (3) information in the header\n",
    "        delkey = []\n",
    "        for key in hdr2d.keys():\n",
    "            if len(key) != 0 and key[-1] == '3': delkey.append(key)\n",
    "        for i in delkey: del hdr2d[i]\n",
    "\n",
    "        hdr2d['NAXIS'] = 2\n",
    "        if 'WCSAXES' in hdr2d.keys(): hdr2d['WCSAXES']=2\n",
    "        # create a 1D header (vel) to parse the velocity using astropy.wcs\n",
    "        hdr1d = header.copy()\n",
    "        # we don't need the RA/DEC keywords info in the header now.\n",
    "        delkey = []\n",
    "        for keya in hdr1d.keys():\n",
    "            if len(keya) != 0 and keya[-1] in ['1', '2']: delkey.append(keya)\n",
    "        for i in delkey: del hdr1d[i]\n",
    "        delkey = []\n",
    "        for keyb in hdr1d.keys():\n",
    "            if len(keyb) != 0 and keyb[-1] == '3':\n",
    "                hdr1d.append('%s1'%(keyb[:-1]))\n",
    "                hdr1d['%s1'%(keyb[:-1])] = hdr1d[keyb]\n",
    "                delkey.append(keyb)\n",
    "        for i in delkey: del hdr1d[i]\n",
    "        hdr1d['NAXIS'] = 1\n",
    "        if 'WCSAXES' in hdr1d.keys(): hdr1d['WCSAXES']=1\n",
    "\n",
    "        # save header arrays\n",
    "        hdrarrs.append(hdr2d)\n",
    "        hdrarrs.append(hdr1d)\n",
    "    else:\n",
    "        print(\"This code can only handle 2D or 3D data\")\n",
    "        sys.exit(1)\n",
    "\n",
    "    return_arrays = []\n",
    "\n",
    "    # calculate RA, DEC\n",
    "    gwcsa = wcs.WCS(hdr2d)\n",
    "    n1, n2 = hdr2d['NAXIS1'], hdr2d['NAXIS2']\n",
    "    ax = np.reshape(np.mgrid[0:n1:1]+1, (1, n1))  # For FITS standard, origin = 1\n",
    "    ay = np.reshape(np.mgrid[0:n2:1]+1, (n2, 1))  #   then for numpy standard, origin = 0\n",
    "    coor1, coor2 = gwcsa.all_pix2world(ax, ay, 1) # coor1 = ra  or glon\n",
    "    return_arrays.append(coor1)                   # coor2 = dec or glat\n",
    "    return_arrays.append(coor2)\n",
    "\n",
    "    ## calculate VLSR\n",
    "    if header['NAXIS'] == 3:\n",
    "        gwcsb = wcs.WCS(hdr1d)\n",
    "        n1 = hdr1d['NAXIS1']\n",
    "        ax = np.mgrid[0:n1:1]+1\n",
    "        # ax = np.linspace(0, n1, n1)  # nope, wrong\n",
    "        vel = gwcsb.all_pix2world(ax, 1)[0]\n",
    "        if 'CUNIT1' in hdr1d.keys():\n",
    "            if hdr1d['CUNIT1'] in ['m/s', 'M/S', 'M/s', 'm/S']:\n",
    "                vel = vel/1e3\n",
    "        else: vel = vel/1e3  # default is usually in m/s\n",
    "        return_arrays.append(vel)\n",
    "\n",
    "    if returnHeader == True: return_arrays.append(hdrarrs)\n",
    "    return return_arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ellipse_mask_cube(semi_a, semi_b, PA, tar_x, tar_y, cube_header, extend_pix = 0):\n",
    "    ## make ellipse based on the semi major/minor axies and position angle of the targets \n",
    "    \n",
    "    cube_wh = cube_header['NAXIS1']  # RA\n",
    "    cube_ht = cube_header['NAXIS2']  # DEC\n",
    "    x1d = np.arange(cube_wh)\n",
    "    y1d = np.arange(cube_ht)\n",
    "    x2d, y2d = np.meshgrid(x1d, y1d)\n",
    "\n",
    "    # center at the source \n",
    "    x2d_nc, y2d_nc = x2d-tar_x, y2d-tar_y\n",
    "\n",
    "    # this is a rough pixel length for the semimajor and semiminor axis\n",
    "    semi_a_pix = ceil(abs(semi_a / cube_header['CDELT1']))\n",
    "    semi_b_pix = ceil(abs(semi_b / cube_header['CDELT1']))\n",
    "    \n",
    "    #phi = np.radians(90-PA) changing \n",
    "    phi = np.radians(90+PA)\n",
    "\n",
    "    # transform to new coordinate system\n",
    "    xx_prime = x2d_nc*np.cos(phi) + y2d_nc*np.sin(phi)\n",
    "    yy_prime = -x2d_nc*np.sin(phi) + y2d_nc*np.cos(phi)\n",
    "\n",
    "    mask_ep = ((xx_prime/(semi_a_pix+extend_pix))**2 + (yy_prime/(semi_b_pix+extend_pix))**2)<=1 \n",
    "    return mask_ep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YES, we find it!!! 0.4917 -15.4608 -130000\n"
     ]
    }
   ],
   "source": [
    "def find_info(objname):\n",
    "    from astropy.table import Table \n",
    "    tb = Table.read('/Users/amalyajohnson/Desktop/astro/Dwarf Galaxies/dwarfgalcomplete.txt', format='ascii')\n",
    "    \n",
    "    newname = objname.replace('*','').replace('(','').replace(')', '').replace(' ', '')\n",
    "    for i, iname in enumerate(tb['GalaxyName']):\n",
    "        i_tbnewname = iname.replace('*','').replace('(','').replace(')', '').replace(' ', '')\n",
    "        \n",
    "        if newname == i_tbnewname:\n",
    "            find_it = True\n",
    "            break\n",
    "        else: \n",
    "            find_it = False\n",
    "            \n",
    "    if find_it == True:\n",
    "        print('YES, we find it!!!', tb['RA'][i], tb['DEC'][i], tb['vh(m/s)'][i])\n",
    "        return tb['RA'][i], tb['DEC'][i], tb['vh(m/s)'][i], tb['rh(arcmins)'][i], tb['e=1-b/a'][i], tb['PA'][i]\n",
    "    else:\n",
    "        print('Sorry, not there, check your object name. ')\n",
    "        return np.nan, np.nan, np.nan\n",
    "    \n",
    "    \n",
    "# Galaxy  info\n",
    "\n",
    "objname = 'WLM'\n",
    "#objRA, objDEC objV = 132.874, 63.13, -116000\n",
    "#semi_a = .073 # degree, semi major axes\n",
    "#semi_b = .03796 # degree, semi minor axes\n",
    "#PA = 85      # degree, I suppose it's angle between semi_a and north, measured toward east? \n",
    "\n",
    "### \n",
    "objRA, objDEC, objV_helio, a, ecc, PA = find_info(objname)\n",
    "vcoord = vhelio2vlsr_Westmeier(0, objRA, objDEC, doradec=True) # in km/s\n",
    "objV = objV_helio + vcoord*1e3\n",
    "semi_b = (1 - ecc)*a/60\n",
    "semi_a = a/60 \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: VerifyWarning: Invalid 'BLANK' keyword in header.  The 'BLANK' keyword is only applicable to integer data, and will be ignored in this HDU. [astropy.io.fits.hdu.image]\n"
     ]
    }
   ],
   "source": [
    "cubename = '/Users/amalyajohnson/Desktop/datacubes/hi4pi need//CAR_D01.fits'\n",
    "img1 = fits.getdata(cubename)\n",
    "hdr = fits.getheader(cubename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((933, 266, 266), 362, 247, 186)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# setting up the WCS\n",
    "wcsleop =  wcs.WCS(hdr)\n",
    " \n",
    "\n",
    "# converting to pixel space\n",
    "tar_x, tar_y, tar_v = wcsleop.all_world2pix(objRA, objDEC, objV, 0)\n",
    "tar_x = int(tar_x)\n",
    "tar_y = int(tar_y)\n",
    "tar_v = int(tar_v)\n",
    "# & checking it's in there\n",
    "img1.shape,  tar_v, tar_x, tar_y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.14366666666666666, 0.064649999999999985)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## figure out how large the area surrounding the source that we want \n",
    "ep1 = ellipse_mask_cube(semi_a, semi_b, PA, tar_x, tar_y, hdr, extend_pix=0)\n",
    "ep2 = ellipse_mask_cube(.25, .25, PA, tar_x, tar_y, hdr, extend_pix=0)\n",
    "\n",
    "#ep3 if need to go bigger/smaller (resolved detected)\n",
    "ep3 = ellipse_mask_cube(semi_a, semi_b, PA, tar_x, tar_y, hdr, extend_pix=2)\n",
    "\n",
    "#ep3 beamsize (unresolved detected)\n",
    "#ep3 = ellipse_mask_cube(0.133333, 0.133333, PA, tar_x, tar_y, hdr, extend_pix=0) #hi4pi\n",
    "#ep3 = ellipse_mask_cube(0.0333333, 0.0333333, PA, tar_x, tar_y, hdr, extend_pix=0) #galfa\n",
    "\n",
    "\n",
    "a = img1[tar_v][ep1]\n",
    "b = img1[tar_v][ep2]\n",
    "semi_a, semi_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1349.1046"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def vel_width(objname):\n",
    "    tb = Table.read('/Users/amalyajohnson/Desktop/astro/Dwarf Galaxies/dwarfgalcomplete_newnew.txt', format='ascii')    \n",
    "    \n",
    "    for i, iname in enumerate(tb['GalaxyName']):        \n",
    "        if iname == objname:\n",
    "            find_it = True\n",
    "            break\n",
    "        else: \n",
    "            find_it = False\n",
    "            \n",
    "    if find_it == True:\n",
    "        sig = float(tb['sigma_g(km/s)'][i])\n",
    "        fwhm = sig*2.355\n",
    "        #hi4pi = 1.29\n",
    "        galfa = .736\n",
    "        v_width = fwhm/galfa #or galfa\n",
    "        print('found', objname, sig, fwhm, v_width)\n",
    "        return ceil(v_width) # x would be an int \n",
    "    else:\n",
    "        print('Sorry, not there, check your object name. ')\n",
    "        return np.nan, np.nan, np.nan\n",
    "        \n",
    "x = 60 #vel_width(objname)\n",
    "\n",
    "## if x is odd number,  add 1 to it \n",
    "if np.mod(x, 2) == 1: x=x+1 \n",
    "\n",
    "full_chan = tar_v + np.arange(x+1) - ceil(x/2)\n",
    "vrange = []\n",
    "vrange_std = []\n",
    "for iv in full_chan:\n",
    "    v_chan  = img1[iv][ep2] #changed to 2 for a WLM \n",
    "    v_std = np.nanstd(v_chan)\n",
    "    vrange.append(v_chan)\n",
    "    vrange_std.append(v_std)\n",
    "    \n",
    "vrange = np.asarray(vrange)\n",
    "vrange_std = np.asarray(vrange_std)\n",
    "vrange_sum = np.nansum(vrange)\n",
    "\n",
    "#print(vrange_std, vrange)\n",
    "vrange_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 8))\n",
    "im = plt.imshow(img1[tar_v, :, :], cmap='jet', origin='lower') #, vmin=-.4, vmax=.4)\n",
    "plt.contour(ep1, colors='white')\n",
    "plt.contour(ep2, colors='r') #, alpha=0.1)\n",
    "plt.contour(ep3, colors='white') #, alpha=0.1)\n",
    "\n",
    "plt.text(tar_x+15, tar_y+15, objname, color='w', fontsize=14, weight='semibold')\n",
    "plt.title(objname)\n",
    "plt.colorbar(im)\n",
    "\n",
    "#plt.xlim(200, 250)\n",
    "#plt.ylim(125, 175)\n",
    "\n",
    "#plt.savefig('/Users/amalyajohnson/Desktop/images/%s_image2.pdf'%(objname))\n",
    "#plt.savefig('/Users/amalyajohnson/Desktop/test.pdf')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dist = 769.13/1e3\n",
    "tflux = 433.7005\n",
    "tmasssolar = tflux*hdr['CDELT3']/1000.*1.8e18*np.cos(objDEC*np.pi/180.)*(hdr['CDELT2']*np.pi/180.*dist*u.pc.in_units('cm')*1e6)**2*1.6727e-24/1.99e33\n",
    "tmasssolar/1e6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#a velocity channels\n",
    "a_1 = (img1[tar_v-5][ep1])\n",
    "a_2 = (img1[tar_v-4][ep1])\n",
    "a_3 = (img1[tar_v-3][ep1])\n",
    "a_4 = (img1[tar_v-2][ep1])\n",
    "a_5 = (img1[tar_v-1][ep1])\n",
    "a_6 = (img1[tar_v][ep1])\n",
    "a_7 = (img1[tar_v+1][ep1])\n",
    "a_8 = (img1[tar_v+2][ep1])\n",
    "a_9 = (img1[tar_v+3][ep1])\n",
    "a_10 = (img1[tar_v+4][ep1])\n",
    "a_11 = (img1[tar_v+5][ep1])\n",
    "arange = np.array([a_1, a_2, a_3, a_4, a_5, a_6, a_7, a_8, a_9, a_10, a_11])\n",
    "arange_std = np.array([np.nanstd(a_1), np.nanstd(a_2), np.nanstd(a_3), np.nanstd(a_4),\n",
    "                       np.nanstd(a_5), np.nanstd(a_6), np.nanstd(a_7), np.nanstd(a_8),\n",
    "                       np.nanstd(a_9), np.nanstd(a_10), np.nanstd(a_11)])\n",
    "\n",
    "\n",
    "#b velocity channels     \n",
    "b_1 = (img1[tar_v-5][ep2])\n",
    "b_2 = (img1[tar_v-4][ep2])\n",
    "b_3 = (img1[tar_v-3][ep2])\n",
    "b_4 = (img1[tar_v-2][ep2])\n",
    "b_5 = (img1[tar_v-1][ep2])\n",
    "b_6 = (img1[tar_v][ep2])\n",
    "b_7 = (img1[tar_v+1][ep2])\n",
    "b_8 = (img1[tar_v+2][ep2])\n",
    "b_9 = (img1[tar_v+3][ep2])\n",
    "b_10 = (img1[tar_v+4][ep2])\n",
    "b_11 = (img1[tar_v+5][ep2])\n",
    "brange = np.array([b_1, b_2, b_3, b_4, b_5, b_6, b_7, b_8, b_9, b_10, b_11])\n",
    "brange_std = np.array([np.nanstd(b_1), np.nanstd(b_2), np.nanstd(b_3), np.nanstd(b_4), \n",
    "                       np.nanstd(b_5), np.nanstd(b_6), np.nanstd(b_7), np.nanstd(b_8), \n",
    "                       np.nanstd(b_9), np.nanstd(b_10), np.nanstd(b_11)])\n",
    "\n",
    "std_a = np.nanstd(a)\n",
    "med_stda = np.nanmedian(arange_std)\n",
    "std_b = np.nanstd(b)\n",
    "med_stdb = np.nanmedian(brange_std)\n",
    "tflux_a = np.nansum(arange) #flux throughout  entire velocity range of +/- 5 channels\n",
    "med_tfluxa = np.nanmedian(arange)\n",
    "tflux_b = np.nansum(brange)\n",
    "med_tfluxb = np.nanmedian(brange)\n",
    "flux_a = np.nansum(a)\n",
    "flux_b = np.nansum(b)\n",
    "\n",
    "print(med_stdb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#UNRESOLVED DETECTED\n",
    "\n",
    "#hi4pi\n",
    "ep3 = ellipse_mask_cube(0.133333, 0.133333, PA, tar_x, tar_y, hdr, extend_pix=0)\n",
    "\n",
    "#galfa\n",
    "#ep3 = ellipse_mask_cube(0.0333333, 0.0333333, PA, tar_x, tar_y, hdr, extend_pix=0)\n",
    "\n",
    "c = img1[tar_v][ep3]\n",
    "\n",
    "#c velocity channels\n",
    "c_1 = (img1[tar_v-5][ep3])\n",
    "c_2 = (img1[tar_v-4][ep3])\n",
    "c_3 = (img1[tar_v-3][ep3])\n",
    "c_4 = (img1[tar_v-2][ep3])\n",
    "c_5 = (img1[tar_v-1][ep3])\n",
    "c_6 = (img1[tar_v][ep3])\n",
    "c_7 = (img1[tar_v+1][ep3])\n",
    "c_8 = (img1[tar_v+2][ep3])\n",
    "c_9 = (img1[tar_v+3][ep3])\n",
    "c_10 = (img1[tar_v+4][ep3])\n",
    "c_11 = (img1[tar_v+5][ep3])\n",
    "                                   \n",
    "crange = np.array([c_1, c_2, c_3, c_4, c_5, c_6, c_7, c_8, c_9, c_10, c_11])\n",
    "crange_std = np.array([np.nanstd(c_1), np.nanstd(c_2), np.nanstd(c_3), np.nanstd(c_4),\n",
    "                       np.nanstd(c_5), np.nanstd(c_6), np.nanstd(c_7), np.nanstd(c_8),\n",
    "                       np.nanstd(c_9), np.nanstd(c_10), np.nanstd(c_11)])\n",
    "\n",
    "std_c = np.nanstd(c)\n",
    "med_stdc = np.nanmedian(crange_std)\n",
    "tflux_c = np.nansum(crange) #flux throughout  entire velocity range of +/- 5 channels\n",
    "med_tfluxc = np.nanmedian(crange)\n",
    "flux_c = np.nansum(c)\n",
    "\n",
    "#flux_c, tflux_c, flux_a, tflux_a\n",
    "c.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 8))\n",
    "im = plt.imshow(img1[tar_v, :, :], cmap='jet', origin='lower', vmin=-.5, vmax=.5)\n",
    "plt.contour(ep1, colors='white')\n",
    "plt.contour(ep2, colors='r') #, alpha=0.1)\n",
    "plt.text(tar_x+15, tar_y+15, objname, color='w', fontsize=14, weight='semibold')\n",
    "plt.title(objname)\n",
    "plt.colorbar(im)\n",
    "\n",
    "plt.contour(ep3, colors='k', alpha=.5) #for unresolved detected\n",
    "\n",
    "#plt.xlim(200, 265)\n",
    "#plt.ylim(125, 200)\n",
    "\n",
    "#plt.savefig('/Users/amalyajohnson/Desktop/images/%s_image2.pdf'%(objname))\n",
    "#plt.savefig('/Users/amalyajohnson/Desktop/test.pdf')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tables (from other notebook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#GALDATA NEW\n",
    "#tbnew = Table(names=('GalaxyName', 'std', 'std_med', 'std30', 'std30_med', 'flux', 'tflux', 'tflux_med', 'flux30', 'tflux30', 'tflux30_med'), meta={'name': 'first table'},dtype=('<U11', 'f8', 'f8', 'f8', 'f8', 'f8', 'f8', 'f8', 'f8', 'f8', 'f8'))\n",
    "#tbnew = Table.read('/Users/amalyajohnson/Desktop/astro/Dwarf Galaxies/galdata_new.txt', format='ascii')\n",
    "#row = np.array([objname, std_a, med_stda, std_b, med_stdb, flux_a, tflux_a, med_tfluxa, flux_b, tflux_b, med_tfluxb])\n",
    "#tbnew.add_row(row)\n",
    "\n",
    "#tbnew\n",
    "#f = open('galdata_new.txt', 'w')\n",
    "#table = tbnew\n",
    "#f.write(tabulate(tbnew))\n",
    "#f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#tbv = Table.read('/Users/amalyajohnson/Desktop/astro/Dwarf Galaxies/stds.txt', format='ascii')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rowv = np.array([objname, np.nanstd(a_1), np.nanstd(a_2), np.nanstd(a_3), np.nanstd(a_4),\n",
    "                       np.nanstd(a_5), np.nanstd(a_6), np.nanstd(a_7), np.nanstd(a_8),\n",
    "                       np.nanstd(a_9), np.nanstd(a_10), np.nanstd(a_11)])\n",
    "rowv_ex = np.array(['%s_ex'%(objname), np.nanstd(b_1), np.nanstd(b_2), np.nanstd(b_3), np.nanstd(b_4), \n",
    "                       np.nanstd(b_5), np.nanstd(b_6), np.nanstd(b_7), np.nanstd(b_8), \n",
    "                      np.nanstd(b_9), np.nanstd(b_10), np.nanstd(b_11)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tbv.add_row(rowv)\n",
    "tbv.add_row(rowv_ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = open('stds.txt', 'w')\n",
    "table = tbv\n",
    "f.write(tabulate(tbv))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
